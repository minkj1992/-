# Python


## python의 동작방식

## 파이썬 generator에 대해 아는 만큼 설명해주세요.
- iterator의 일종
- 일반적인 함수의 진입점이 1개라면, 제너레이터 함수는 진입점이 여러개인 함수
- `yield 구문`을 사용해 데이터를 원하는 시점에 반환하고 처리를 다시 시작할 수 있다.
- 장점
    - 효율적인 메모리 사용
- 단점
    - next() 사용 후, 휘발된다.

- `send()`
    - coroutine에 활용된다.
    - 제너레이터에 값을 전달(재진입 가능)


## 파이썬에서 클래스를 상속하면, 메서드는 어떤 식으로 실행되나요?
인스턴스의 메서드를 실행한다면 `__getattribute__()`로 bound된 method를 가져온 후 실행합니다. 이때 method 호출 순서는 `MRO`(Method Resolution Order)를 따릅니다.
```
https://corikachu.github.io/articles/python/python-magic-method

__getattr__(self, name): 객체의 없는 속성을 참조하려 할때 호출됩니다. 일반적으로 찾는 속성이 있다면 호출되지 않습니다. __getattr__은 인스턴스의 다른 속성에는 접근 할 수 없도록 설계 되어있습니다.

__getattribute__(self, name): 객체의 속성을 호출할때 무조건 호출됩니다. 만약 이 메소드가 재정의 되어있다면 __getattr__는 호출되지 않으므로 명시적으로 호출해야하거나 AttributeError에러를 발생시켜야합니다.
```
## 파이썬에 존재하는 GIL에 대해서 설명해주세요.
- `GIL`이란 Global Interpreter Lock.
- 스레드에 사용되는 `Lock`를 인터프리터 레벨로 확장
- 어느 시점이든 하나의 `Bytecode`만 실행되도록 강제한다.
- 싱글 스레드로 동작한다.

- `문제점`
    - 1) `CPU bound`(cpu의 영향이 큰 작업)인 task를 멀티스레드로 수행하도록 한 경우 문제가 생긴다. 이를 해결하기 위해선 멀티 스레드는 파일, 네트워크 IO 같은 IO bound 프로그램에 사용하고 멀티 프로세스(병렬성)를 활용해야한다.

    - `c.f)` python은 `I/O system call`발생 시, GIL을 해제하고 
    다른 GIL 획득 thread로 제어권이 넘어간다.

    - 2) 어떤  thread로 넘어갈지 Random
        - 시스템이 제공하는 방식에 따라 `context switching`이 발생
        - `greenlet`은 explicit scheduling(명시적)이 가능
- `GIL의 장점`
    - 타 멀티 스레드에 비해 간편한 구현
    - 싱글 스레드 성능 우월
    - C extension을 활용 시 GIL 해제되므로, C lib를 사용하는 CPU bound 프로그램을 멀티 스레드로 실행하는 경우 더 빠를 수 있다.


## 동시성(Concurrency) vs 병렬성(Parallelism)
[gevent](https://hamait.tistory.com/756?category=79136)
[네이버강연자료](https://www.slideshare.net/deview/2d4python)

- `병렬성`(Parallelism): 특정 순간에 task들을 동시에 처리가능(하드웨어 의존적, 싱글코어에서는 불가능)
- `동시성`(Councurrency): 스케줄링을 통하여 여러 Task들을 동시에 처리하는 것처럼 보이나, 특정 순간에 하나의 Task만을 처리하고 있다. 
    - 멀티 스레딩 / 멀티 프로세싱
    - 
- CPU Bound는 multiprocessing(병렬성)
- I/O Bound는 비동기처리 up

- 파이썬은 `multithreading`이 아닌 `multiprocessing`을 활용해 병렬성 제공(Queue,Pipe,Lock,Shared Memory,Pool)

파이썬은 기본적으로 GIL에 의하여 싱글스레드에서는 최적의 효율을 내지만, 멀티쓰레드 환경은 GIL LOCK에 의하여 싱글 스레드보다 성능 효율이 떨어지게 된다. 그리하여 동시성과 병렬성에 대한 파이썬 만의 고찰이 필요하다.

기본적으로 프로세스는 2가지 성격, I/O Bound와 Cpu Bound한 태스크가 존재하는데, I/O Bound의 경우에는 기본적으로 lock에 의해 wait 시간 overhead가 발생하며, cpu bound의 경우에는 wait 타임이 존재하지 않아, 하나의 코어에서 자주 switch 해주는 것이 overhead를 증가시키는 결과를 낳는다.

사실 I/O bound 한 작업을 하게되어 block으로 스레드가 들어가게 되면 파이썬의 GIL은 Release 하게 되어, 멀티스레딩 방식으로 I/O한 작업들을 실행 할 수있다. 다만 여기서 문제점은 개발자가 원하는 시점에 I/O작업을 마친 Thread가 GIL을 획득한다는 보장이 없다는 것이다. 이를 해결하기 위해 python에서는 `coroutine`을 사용한 `asyncio`(coroutine(explicit scheduling), event-driven, cooperative Multitasking), `gevent`(promise) 라이브러리가 등장하였다. coroutine이란 제너레이터의 yield 특성과, `=yield`를 통하여 `input`을 추가해주는 기술이 있어, 개발자가 원하는 시점에 제어권을 획득하도록 강제할 수 있다. 이를 통하여 `yield 비동기 event()`를 해주어 특정 비동기 스레드로부터 작업이 완료되면 yield를 통하여 GIL을 획득하는 방식으로 효율을 극대화 할 수 있다.

CPU bound의 경우에는 multiprocessing을 사용하여 여러 코어(CPU)에 접근가능할 수 있다.

## 파이썬의 GC 작동 방식
> 
- [pyhton gc](https://winterj.me/python-gc/)
- [instagram and GC and GIL](https://alex.dzyoba.com/blog/arc-vs-gc/)
- [instagram 번역 + 개인 견해](https://b.luavis.kr/python/dismissing-python-garbage-collection-at-instagram)
- [python gc collect()](https://www.quora.com/How-does-garbage-collection-in-Python-work-What-are-the-pros-and-cons)



- gc = `reference counting`, `cyclic reference `
기본적으로 gc는 1)Tracing 2) ref counting 기법이 있으며, 파이썬의 경우는 후자이다.
- Tracing: JAVA, ref_cnt에 비해 빠르지만 메모리 소모가 크고 지속적으로 돌아가야 하며(백그라운드로 멀티스레딩) 상대적으로 longer `stop the world`(freeze)가 발생한다.
- Ref cnting: Python, less mem and stop-the-world(freeze)이 장점이며 단점으로 1) 각 객체당 var ref_cnt 오버헤드(그리 크기 않다.) 2)concurrency issue(멀티스레딩 방식으로 ref_counting을 실시하면 synchronisation) 3) leak mem 해소를 위한 cycle detector가 필요


파이썬의 경우는 GIL을 통해서 SYNC가 필요없기 때문에, 3) cycle 문제만 해결하면 되며 그리하여 gc 모듈은 `Cycle detect`만 실시한다.
전반적으로 파이썬의 객체가 생성 요청이 되면 `_PyObject_GC_Alloc(void)` -> `collect_generations(void)` -> `collect_with_callback(int generation)` -> `collect(generation, &collected, &uncollectable, 0)`(=cycle detect)형식으로 진행이 된다.



c.f) 추가적으로 파이썬은 객체를 3가지 영역으로 구분하여 관리하는데, 이는 `generational hypothesis`라고 하여 `‘object die young’ or ‘are likely to live forever’`, 이며 풀어서 객체는 초기에 더 많이 죽으며 오래된 객체일 수록 더 오래산다는 말이다. 이러한 가정에 따라서 파이썬은 0~3세대로 구분 지어서 메모리 관리를 실시하며, 각 세대마다 Threshold(700,10,10)와 counter가 존재한다. 1세대의 경우는 0세대가 10번 move하면 counter가 Threshold를 초과하게 되어 gc가 돌아가게 되는 식인데, 직접적으로 0세대는 700번 단위로 1세대는 7000번 단위로 2세대는 70000번 단위로 gc를 불러주게 된다.


> gc는 언제 작동하는가?
0세대의 경우 `generation[0].count(객체 할당 횟수- 객체 free횟수) > Threshold[0]`일경우 GC를 실행시킨다. 파이썬은 새로운 객체가 생성될 때 마다 `_PyObject_GC_Alloc()`을 호출하여 이를 통해 객체를 mem에 할당하고, `gc.generation[0].count++`시켜준다. 이후 Threshold[0]보다 크다+ 기본상태조건 -> `collect_generations()`를 불러주어 2세대 부터 임계치를 확인하여 만약 넘는다면 `collect_with_callback(세대)`를 불러주고 break(collect가 해당 세대부터 0세대까지 통합하여 검사를 실시하므로)를 건다. `collect_with_callback`은 `collect()`을 불러주어 uncollectable(=unreachable, 삭제할 녀석들)을 파악한 뒤, callback을 수행한 후 메모리에서 해제시킨다. 이제 핵심적인 `collect()`함수를 알아보자.

> gc는 어떻게 cyclic reference를 감지하는가?
우선 순환참조(cyclic ref)는 파이썬의 경우 컨테이너 객체(tuple,list,set,dict,class)에 의해서만 발생할 수 있다.(오직 컨체이너 객체만이 다른 객체에 대한 reference를 보유 가능) 그리하여 pyhton gc모듈은 `PyGC_Head`라는 더블 링크드 리스트(삽입,삭제 효율적) 구조체를 선언하여 컨테이너 객체가 생성될 때마다, 서로 연결지어준다.

- `_gc_head`


```C++
typedef union _gc_head {
    struct {
        union _gc_head *gc_next;
        union _gc_head *gc_prev;
        Py_ssize_t gc_refs;
    } gc;
    double dummy;  /* force worst-case alignment */
} PyGC_Head;
```
`Collect()`함수는 아래 알고리즘을 따라서 generation[:args+1]을 통합하여 검사를 실시한다.

**순환 알고리즘**
```
young = generation[:args+1]
1. update_refs(young)   컨테이너 객체의 `gc_refs`필드를 실제 ref_cnt와 같게 초기화한다.
2. subtract_refs(young) 각 객체에서 참조하는 다른 녀석들의 ref를 - 시켜준다.
3. gc_init_list(unreachable)
4. move_unreachable(young,&unrechable)  만약 subtract이후에 ref값이 남아있다는 것은, 다른 generation에서 이를 ref한다는 것이므로 살려주어야 한다. 또한 살린 녀석들의 reference들 또한 살려주어야 한다. 이때 leftover들이 cyclic한 컨테이너이므로 free 시켜준다.
```

<details>
<summary>Collect()</summary>

```C++
collect(struct _gc_runtime_state *state, int generation,
        Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable, int nofail)
{
    int i;
    Py_ssize_t m = 0; /* # objects collected */
    Py_ssize_t n = 0; /* # unreachable objects that couldn't be collected */
    PyGC_Head *young; /* the generation we are examining */
    PyGC_Head *old; /* next older generation */
    PyGC_Head unreachable; /* non-problematic unreachable trash */
    PyGC_Head finalizers;  /* objects with, & reachable from, __del__ */
    PyGC_Head *gc;
    _PyTime_t t1 = 0;   /* initialize to prevent a compiler warning */

    if (state->debug & DEBUG_STATS) {
        PySys_WriteStderr("gc: collecting generation %d...\n", generation);
        show_stats_each_generations(state);
        t1 = _PyTime_GetMonotonicClock();
    }

    if (PyDTrace_GC_START_ENABLED())
        PyDTrace_GC_START(generation);

    /* update collection and allocation counters */
    if (generation+1 < NUM_GENERATIONS)
        state->generations[generation+1].count += 1;
    for (i = 0; i <= generation; i++)
        state->generations[i].count = 0;

    /* merge younger generations with one we are currently collecting */
    for (i = 0; i < generation; i++) {
        gc_list_merge(GEN_HEAD(state, i), GEN_HEAD(state, generation));
    }

    /* handy references */
    young = GEN_HEAD(state, generation);
    if (generation < NUM_GENERATIONS-1)
        old = GEN_HEAD(state, generation+1);
    else
        old = young;
    validate_list(old, 0, 0);

    deduce_unreachable(young, &unreachable);

    untrack_tuples(young);
    /* Move reachable objects to next generation. */
    if (young != old) {
        if (generation == NUM_GENERATIONS - 2) {
            state->long_lived_pending += gc_list_size(young);
        }
        gc_list_merge(young, old);
    }
    else {
        /* We only untrack dicts in full collections, to avoid quadratic
           dict build-up. See issue #14775. */
        untrack_dicts(young);
        state->long_lived_pending = 0;
        state->long_lived_total = gc_list_size(young);
    }

    /* All objects in unreachable are trash, but objects reachable from
     * legacy finalizers (e.g. tp_del) can't safely be deleted.
     */
    gc_list_init(&finalizers);
    // NEXT_MASK_UNREACHABLE is cleared here.
    // After move_legacy_finalizers(), unreachable is normal list.
    move_legacy_finalizers(&unreachable, &finalizers);
    /* finalizers contains the unreachable objects with a legacy finalizer;
     * unreachable objects reachable *from* those are also uncollectable,
     * and we move those into the finalizers list too.
     */
    move_legacy_finalizer_reachable(&finalizers);

    validate_list(&finalizers, 0, 0);
    validate_list(&unreachable, PREV_MASK_COLLECTING, 0);

    /* Print debugging information. */
    if (state->debug & DEBUG_COLLECTABLE) {
        for (gc = GC_NEXT(&unreachable); gc != &unreachable; gc = GC_NEXT(gc)) {
            debug_cycle("collectable", FROM_GC(gc));
        }
    }

    /* Clear weakrefs and invoke callbacks as necessary. */
    m += handle_weakrefs(&unreachable, old);

    validate_list(old, 0, 0);
    validate_list(&unreachable, PREV_MASK_COLLECTING, 0);

    /* Call tp_finalize on objects which have one. */
    finalize_garbage(&unreachable);

    /* Handle any objects that may have resurrected after the call
     * to 'finalize_garbage' and continue the collection with the
     * objects that are still unreachable */
    PyGC_Head final_unreachable;
    handle_resurrected_objects(&unreachable, &final_unreachable, old);

    /* Call tp_clear on objects in the final_unreachable set.  This will cause
    * the reference cycles to be broken.  It may also cause some objects
    * in finalizers to be freed.
    */
    m += gc_list_size(&final_unreachable);
    delete_garbage(state, &final_unreachable, old);

    /* Collect statistics on uncollectable objects found and print
     * debugging information. */
    for (gc = GC_NEXT(&finalizers); gc != &finalizers; gc = GC_NEXT(gc)) {
        n++;
        if (state->debug & DEBUG_UNCOLLECTABLE)
            debug_cycle("uncollectable", FROM_GC(gc));
    }
    if (state->debug & DEBUG_STATS) {
        double d = _PyTime_AsSecondsDouble(_PyTime_GetMonotonicClock() - t1);
        PySys_WriteStderr(
            "gc: done, %" PY_FORMAT_SIZE_T "d unreachable, "
            "%" PY_FORMAT_SIZE_T "d uncollectable, %.4fs elapsed\n",
            n+m, n, d);
    }

    /* Append instances in the uncollectable set to a Python
     * reachable list of garbage.  The programmer has to deal with
     * this if they insist on creating this type of structure.
     */
    handle_legacy_finalizers(state, &finalizers, old);
    validate_list(old, 0, 0);

    /* Clear free list only during the collection of the highest
     * generation */
    if (generation == NUM_GENERATIONS-1) {
        clear_freelists();
    }

    if (PyErr_Occurred()) {
        if (nofail) {
            PyErr_Clear();
        }
        else {
            if (gc_str == NULL)
                gc_str = PyUnicode_FromString("garbage collection");
            PyErr_WriteUnraisable(gc_str);
            Py_FatalError("unexpected exception during garbage collection");
        }
    }

    /* Update stats */
    if (n_collected) {
        *n_collected = m;
    }
    if (n_uncollectable) {
        *n_uncollectable = n;
    }

    struct gc_generation_stats *stats = &state->generation_stats[generation];
    stats->collections++;
    stats->collected += m;
    stats->uncollectable += n;

    if (PyDTrace_GC_DONE_ENABLED()) {
        PyDTrace_GC_DONE(n+m);
    }

    assert(!PyErr_Occurred());
    return n+m;
}
```

</details>




## 어떤 request가 Django API까지 도달하는 과정을 최대한 자세히 설명해주세요.
## Django ORM의 작동 방식에 대해 설명해주세요.
## Django ORM에서 지연 평가를 하곤 하는데요. 직접 구현한다면 어떻게 구현하겠습니까?
## http와 https의 차이점은?
## 도커 컨테이너 내부에 nat가 존재할 수 있나요?
## 파이썬 GIL이 무엇이고, 왜 성능 문제가 발생하는가?

## 파이썬의 GC는 어떻게 작동하나요?
## 프로세스와 쓰레드는 어떻게 다른가요?


## 그때 문제는 없었나요?
## pypy는 도대체 왜 CPython보다 빠른 걸까요?

## 웹 서비스 응답이 느리다면 어떻게 해결할 수 있을까요?

## python에서 메모리 릭이 발생할 수 있는 경우는 언제일까요?
## 도커와 VM의 차이점은 뭔가요?


